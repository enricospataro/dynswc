1
00:00:11,845 --> 00:00:16,796
Okay, now I don't want
to alarm anybody in this room,

2
00:00:16,820 --> 00:00:20,796
but it's just come to my attention
that the person to your right is a liar.

3
00:00:20,820 --> 00:00:22,796
(Laughter)

4
00:00:22,820 --> 00:00:25,796
Also, the person to your left is a liar.

5
00:00:25,820 --> 00:00:28,796
Also the person sitting
in your very seats is a liar.

6
00:00:28,820 --> 00:00:30,796
We're all liars.

7
00:00:30,820 --> 00:00:32,796
What I'm going to do today

8
00:00:32,820 --> 00:00:36,396
is I'm going to show you what the research
says about why we're all liars,

9
00:00:36,420 --> 00:00:37,996
how you can become a liespotter

10
00:00:38,020 --> 00:00:40,796
and why you might want
to go the extra mile

11
00:00:40,820 --> 00:00:43,796
and go from liespotting to truth seeking,

12
00:00:43,820 --> 00:00:45,796
and ultimately to trust building.

13
00:00:45,820 --> 00:00:48,796
Now, speaking of trust,

14
00:00:48,820 --> 00:00:51,796
ever since I wrote
this book, "Liespotting,"

15
00:00:51,820 --> 00:00:54,796
no one wants to meet me in person
anymore, no, no, no, no, no.

16
00:00:54,820 --> 00:00:57,796
They say, "It's okay, we'll email you."

17
00:00:57,820 --> 00:00:59,796
(Laughter)

18
00:00:59,820 --> 00:01:03,796
I can't even get
a coffee date at Starbucks.

19
00:01:03,820 --> 00:01:05,796
My husband's like, "Honey, deception?

20
00:01:05,820 --> 00:01:09,011
Maybe you could have focused on cooking.
How about French cooking?"

21
00:01:09,035 --> 00:01:11,178
So before I get started,
what I'm going to do

22
00:01:11,202 --> 00:01:13,796
is I'm going to clarify my goal for you,

23
00:01:13,820 --> 00:01:15,796
which is not to teach a game of Gotcha.

24
00:01:15,820 --> 00:01:17,796
Liespotters aren't those nitpicky kids,

25
00:01:17,820 --> 00:01:21,154
those kids in the back of the room
that are shouting, "Gotcha! Gotcha!

26
00:01:21,178 --> 00:01:23,796
Your eyebrow twitched.
You flared your nostril.

27
00:01:23,820 --> 00:01:26,796
I watch that TV show 'Lie To Me.'
I know you're lying."

28
00:01:26,820 --> 00:01:28,796
No, liespotters are armed

29
00:01:28,820 --> 00:01:31,796
with scientific knowledge
of how to spot deception.

30
00:01:31,820 --> 00:01:33,796
They use it to get to the truth,

31
00:01:33,820 --> 00:01:35,916
and they do what mature
leaders do everyday;

32
00:01:35,940 --> 00:01:38,796
they have difficult conversations
with difficult people,

33
00:01:38,820 --> 00:01:40,796
sometimes during very difficult times.

34
00:01:40,820 --> 00:01:44,796
And they start up that path
by accepting a core proposition,

35
00:01:44,820 --> 00:01:46,796
and that proposition is the following:

36
00:01:46,820 --> 00:01:49,288
Lying is a cooperative act.

37
00:01:50,597 --> 00:01:53,796
Think about it, a lie has no power
whatsoever by its mere utterance.

38
00:01:53,820 --> 00:01:55,796
Its power emerges

39
00:01:55,820 --> 00:01:57,916
when someone else agrees
to believe the lie.

40
00:01:57,940 --> 00:01:59,916
So I know it may sound like tough love,

41
00:01:59,940 --> 00:02:03,796
but look, if at some point
you got lied to,

42
00:02:03,820 --> 00:02:05,796
it's because you agreed to get lied to.

43
00:02:05,820 --> 00:02:08,796
Truth number one about lying:
Lying's a cooperative act.

44
00:02:08,820 --> 00:02:10,796
Now not all lies are harmful.

45
00:02:10,820 --> 00:02:13,796
Sometimes we're willing
participants in deception

46
00:02:13,820 --> 00:02:16,796
for the sake of social dignity,

47
00:02:16,820 --> 00:02:19,796
maybe to keep a secret that should
be kept secret, secret.

48
00:02:19,820 --> 00:02:21,796
We say, "Nice song."

49
00:02:21,820 --> 00:02:24,796
"Honey, you don't look fat in that, no."

50
00:02:24,820 --> 00:02:26,796
Or we say, favorite of the digiratti,

51
00:02:26,820 --> 00:02:29,796
"You know, I just fished
that email out of my Spam folder.

52
00:02:29,820 --> 00:02:32,796
So sorry."

53
00:02:32,820 --> 00:02:36,059
But there are times when we are unwilling
participants in deception.

54
00:02:36,083 --> 00:02:38,796
And that can have dramatic costs for us.

55
00:02:38,820 --> 00:02:41,796
Last year saw 997 billion dollars

56
00:02:41,820 --> 00:02:45,399
in corporate fraud alone
in the United States.

57
00:02:46,153 --> 00:02:48,168
That's an eyelash
under a trillion dollars.

58
00:02:48,192 --> 00:02:49,796
That's seven percent of revenues.

59
00:02:49,820 --> 00:02:51,796
Deception can cost billions.

60
00:02:51,820 --> 00:02:54,796
Think Enron, Madoff, the mortgage crisis.

61
00:02:54,820 --> 00:02:57,796
Or in the case
of double agents and traitors,

62
00:02:57,820 --> 00:02:59,796
like Robert Hanssen or Aldrich Ames,

63
00:02:59,820 --> 00:03:01,796
lies can betray our country,

64
00:03:01,820 --> 00:03:04,820
they can compromise our security,
they can undermine democracy,

65
00:03:04,844 --> 00:03:07,796
they can cause the deaths
of those that defend us.

66
00:03:07,820 --> 00:03:10,796
Deception is actually serious business.

67
00:03:10,820 --> 00:03:14,796
This con man, Henry Oberlander,
he was such an effective con man,

68
00:03:14,820 --> 00:03:16,796
British authorities say

69
00:03:16,820 --> 00:03:20,296
he could have undermined the entire
banking system of the Western world.

70
00:03:20,320 --> 00:03:23,496
And you can't find this guy on Google;
you can't find him anywhere.

71
00:03:23,520 --> 00:03:25,996
He was interviewed once,
and he said the following.

72
00:03:26,020 --> 00:03:27,696
He said, "Look, I've got one rule."

73
00:03:27,720 --> 00:03:29,796
And this was Henry's rule, he said,

74
00:03:29,820 --> 00:03:32,196
"Look, everyone is willing
to give you something.

75
00:03:32,220 --> 00:03:35,792
They're ready to give you something
for whatever it is they're hungry for."

76
00:03:35,816 --> 00:03:37,196
And that's the crux of it.

77
00:03:37,220 --> 00:03:39,649
If you don't want to be
deceived, you have to know,

78
00:03:39,673 --> 00:03:41,349
what is it that you're hungry for?

79
00:03:41,373 --> 00:03:43,796
And we all kind of hate to admit it.

80
00:03:43,820 --> 00:03:46,796
We wish we were
better husbands, better wives,

81
00:03:46,820 --> 00:03:50,796
smarter, more powerful, taller, richer --

82
00:03:50,820 --> 00:03:52,796
the list goes on.

83
00:03:52,820 --> 00:03:54,796
Lying is an attempt to bridge that gap,

84
00:03:54,820 --> 00:03:56,796
to connect our wishes and our fantasies

85
00:03:56,820 --> 00:03:59,796
about who we wish we were,
how we wish we could be,

86
00:03:59,820 --> 00:04:02,796
with what we're really like.

87
00:04:02,820 --> 00:04:06,059
And boy are we willing to fill in
those gaps in our lives with lies.

88
00:04:06,083 --> 00:04:08,796
On a given day, studies show
that you may be lied to

89
00:04:08,820 --> 00:04:10,796
anywhere from 10 to 200 times.

90
00:04:10,820 --> 00:04:13,796
Now granted, many of those are white lies.

91
00:04:13,820 --> 00:04:15,796
But in another study,

92
00:04:15,820 --> 00:04:17,796
it showed that strangers lied three times

93
00:04:17,820 --> 00:04:20,201
within the first 10 minutes
of meeting each other.

94
00:04:20,225 --> 00:04:21,796
(Laughter)

95
00:04:21,820 --> 00:04:24,796
Now when we first hear
this data, we recoil.

96
00:04:24,820 --> 00:04:26,796
We can't believe how prevalent lying is.

97
00:04:26,820 --> 00:04:28,796
We're essentially against lying.

98
00:04:28,820 --> 00:04:32,796
But if you look more closely,
the plot actually thickens.

99
00:04:32,820 --> 00:04:35,796
We lie more to strangers
than we lie to coworkers.

100
00:04:35,820 --> 00:04:39,796
Extroverts lie more than introverts.

101
00:04:39,820 --> 00:04:44,796
Men lie eight times more about themselves
than they do other people.

102
00:04:44,820 --> 00:04:47,796
Women lie more to protect other people.

103
00:04:47,820 --> 00:04:50,796
If you're an average married couple,

104
00:04:50,820 --> 00:04:54,796
you're going to lie to your spouse
in one out of every 10 interactions.

105
00:04:54,820 --> 00:04:56,796
Now, you may think that's bad.

106
00:04:56,820 --> 00:04:59,106
If you're unmarried,
that number drops to three.

107
00:04:59,130 --> 00:05:00,796
Lying's complex.

108
00:05:00,820 --> 00:05:03,820
It's woven into the fabric
of our daily and our business lives.

109
00:05:03,844 --> 00:05:05,796
We're deeply ambivalent about the truth.

110
00:05:05,820 --> 00:05:07,796
We parse it out on an as-needed basis,

111
00:05:07,820 --> 00:05:09,796
sometimes for very good reasons,

112
00:05:09,820 --> 00:05:13,011
other times just because
we don't understand the gaps in our lives.

113
00:05:13,035 --> 00:05:14,796
That's truth number two about lying.

114
00:05:14,820 --> 00:05:16,796
We're against lying,

115
00:05:16,820 --> 00:05:18,796
but we're covertly for it

116
00:05:18,820 --> 00:05:22,820
in ways that our society has sanctioned
for centuries and centuries and centuries.

117
00:05:22,844 --> 00:05:24,796
It's as old as breathing.

118
00:05:24,820 --> 00:05:27,249
It's part of our culture,
it's part of our history.

119
00:05:27,273 --> 00:05:32,796
Think Dante, Shakespeare,
the Bible, News of the World.

120
00:05:32,820 --> 00:05:34,796
(Laughter)

121
00:05:34,820 --> 00:05:37,106
Lying has evolutionary value
to us as a species.

122
00:05:37,130 --> 00:05:40,796
Researchers have long known
that the more intelligent the species,

123
00:05:40,820 --> 00:05:42,796
the larger the neocortex,

124
00:05:42,820 --> 00:05:44,796
the more likely it is to be deceptive.

125
00:05:44,820 --> 00:05:46,796
Now you might remember Koko.

126
00:05:46,820 --> 00:05:50,059
Does anybody remember Koko the gorilla
who was taught sign language?

127
00:05:50,083 --> 00:05:52,796
Koko was taught to communicate
via sign language.

128
00:05:52,820 --> 00:05:54,796
Here's Koko with her kitten.

129
00:05:54,820 --> 00:05:57,796
It's her cute little, fluffy pet kitten.

130
00:05:57,820 --> 00:06:01,796
Koko once blamed her pet kitten
for ripping a sink out of the wall.

131
00:06:01,820 --> 00:06:03,796
(Laughter)

132
00:06:03,820 --> 00:06:06,011
We're hardwired to become
leaders of the pack.

133
00:06:06,035 --> 00:06:07,796
It's starts really, really early.

134
00:06:07,820 --> 00:06:09,796
How early?

135
00:06:09,820 --> 00:06:11,796
Well babies will fake a cry,

136
00:06:11,820 --> 00:06:13,796
pause, wait to see who's coming

137
00:06:13,820 --> 00:06:15,796
and then go right back to crying.

138
00:06:15,820 --> 00:06:17,796
One-year-olds learn concealment.

139
00:06:17,820 --> 00:06:19,796
(Laughter)

140
00:06:19,820 --> 00:06:21,796
Two-year-olds bluff.

141
00:06:21,820 --> 00:06:23,796
Five-year-olds lie outright.

142
00:06:23,820 --> 00:06:25,796
They manipulate via flattery.

143
00:06:25,820 --> 00:06:28,796
Nine-year-olds, masters of the cover-up.

144
00:06:28,820 --> 00:06:30,796
By the time you enter college,

145
00:06:30,820 --> 00:06:34,196
you're going to lie to your mom
in one out of every five interactions.

146
00:06:34,220 --> 00:06:37,096
By the time we enter this work world
and we're breadwinners,

147
00:06:37,120 --> 00:06:40,796
we enter a world that is just cluttered
with Spam, fake digital friends,

148
00:06:40,820 --> 00:06:42,796
partisan media,

149
00:06:42,820 --> 00:06:44,796
ingenious identity thieves,

150
00:06:44,820 --> 00:06:46,796
world-class Ponzi schemers,

151
00:06:46,820 --> 00:06:48,796
a deception epidemic --

152
00:06:48,820 --> 00:06:53,797
in short, what one author calls
a post-truth society.

153
00:06:53,821 --> 00:06:57,786
It's been very confusing
for a long time now.

154
00:07:00,485 --> 00:07:01,796
What do you do?

155
00:07:01,820 --> 00:07:05,796
Well, there are steps we can take
to navigate our way through the morass.

156
00:07:05,820 --> 00:07:08,796
Trained liespotters get to the truth
90 percent of the time.

157
00:07:08,820 --> 00:07:11,796
The rest of us,
we're only 54 percent accurate.

158
00:07:11,820 --> 00:07:13,796
Why is it so easy to learn?

159
00:07:13,820 --> 00:07:16,035
There are good liars and bad liars.

160
00:07:16,059 --> 00:07:17,696
There are no real original liars.

161
00:07:17,720 --> 00:07:20,696
We all make the same mistakes.
We all use the same techniques.

162
00:07:20,720 --> 00:07:24,349
So what I'm going to do is I'm going
to show you two patterns of deception.

163
00:07:24,373 --> 00:07:26,572
And then we're going
to look at the hot spots

164
00:07:26,596 --> 00:07:28,449
and see if we can find them ourselves.

165
00:07:28,473 --> 00:07:30,096
We're going to start with speech.

166
00:07:30,120 --> 00:07:32,454
(Video) Bill Clinton:
I want you to listen to me.

167
00:07:32,478 --> 00:07:33,896
I'm going to say this again.

168
00:07:33,920 --> 00:07:40,796
I did not have sexual relations
with that woman, Miss Lewinsky.

169
00:07:40,820 --> 00:07:44,796
I never told anybody to lie,
not a single time, never.

170
00:07:44,820 --> 00:07:47,796
And these allegations are false.

171
00:07:47,820 --> 00:07:50,392
And I need to go back to work
for the American people.

172
00:07:50,416 --> 00:07:52,392
Thank you.

173
00:07:52,416 --> 00:07:53,928
(Applause)

174
00:07:54,820 --> 00:07:57,796
Pamela Meyer: Okay,
what were the telltale signs?

175
00:07:57,820 --> 00:08:01,796
Well first we heard what's known
as a non-contracted denial.

176
00:08:01,820 --> 00:08:04,820
Studies show that people
who are overdetermined in their denial

177
00:08:04,844 --> 00:08:07,796
will resort to formal rather
than informal language.

178
00:08:07,820 --> 00:08:10,796
We also heard
distancing language: "that woman."

179
00:08:10,820 --> 00:08:13,535
We know that liars will unconsciously
distance themselves

180
00:08:13,559 --> 00:08:14,796
from their subject,

181
00:08:14,820 --> 00:08:17,796
using language as their tool.

182
00:08:17,820 --> 00:08:20,868
Now if Bill Clinton had said,
"Well, to tell you the truth ..."

183
00:08:20,892 --> 00:08:23,183
or Richard Nixon's favorite,
"In all candor ..."

184
00:08:23,207 --> 00:08:24,896
he would have been a dead giveaway

185
00:08:24,920 --> 00:08:26,796
for any liespotter that knows

186
00:08:26,820 --> 00:08:30,249
that qualifying language, as it's called,
qualifying language like that,

187
00:08:30,273 --> 00:08:31,796
further discredits the subject.

188
00:08:31,820 --> 00:08:34,796
Now if he had repeated
the question in its entirety,

189
00:08:34,820 --> 00:08:38,796
or if he had peppered his account
with a little too much detail --

190
00:08:38,820 --> 00:08:41,011
and we're all really glad
he didn't do that --

191
00:08:41,035 --> 00:08:43,035
he would have further discredited himself.

192
00:08:43,059 --> 00:08:44,796
Freud had it right.

193
00:08:44,820 --> 00:08:47,796
Freud said, look,
there's much more to it than speech:

194
00:08:47,820 --> 00:08:50,796
"No mortal can keep a secret.

195
00:08:50,820 --> 00:08:53,796
If his lips are silent,
he chatters with his fingertips."

196
00:08:53,820 --> 00:08:56,796
And we all do it no matter
how powerful you are.

197
00:08:56,820 --> 00:08:58,796
We all chatter with our fingertips.

198
00:08:58,820 --> 00:09:01,796
I'm going to show you
Dominique Strauss-Kahn with Obama

199
00:09:01,820 --> 00:09:04,796
who's chattering with his fingertips.

200
00:09:04,820 --> 00:09:07,796
(Laughter)

201
00:09:07,820 --> 00:09:13,796
Now this brings us to our next pattern,
which is body language.

202
00:09:13,820 --> 00:09:16,796
With body language,
here's what you've got to do.

203
00:09:16,820 --> 00:09:19,796
You've really got to just throw
your assumptions out the door.

204
00:09:19,820 --> 00:09:22,249
Let the science temper
your knowledge a little bit.

205
00:09:22,273 --> 00:09:24,796
Because we think liars
fidget all the time.

206
00:09:24,820 --> 00:09:28,582
Well guess what, they're known to freeze
their upper bodies when they're lying.

207
00:09:28,606 --> 00:09:30,796
We think liars won't look you in the eyes.

208
00:09:30,820 --> 00:09:33,696
Well guess what, they look
you in the eyes a little too much

209
00:09:33,720 --> 00:09:35,296
just to compensate for that myth.

210
00:09:35,320 --> 00:09:38,796
We think warmth and smiles
convey honesty, sincerity.

211
00:09:38,820 --> 00:09:42,796
But a trained liespotter
can spot a fake smile a mile away.

212
00:09:42,820 --> 00:09:45,820
Can you all spot the fake smile here?

213
00:09:46,820 --> 00:09:51,796
You can consciously contract
the muscles in your cheeks.

214
00:09:51,820 --> 00:09:54,796
But the real smile's in the eyes,
the crow's feet of the eyes.

215
00:09:54,820 --> 00:09:56,796
They cannot be consciously contracted,

216
00:09:56,820 --> 00:09:58,796
especially if you overdid the Botox.

217
00:09:58,820 --> 00:10:01,796
Don't overdo the Botox;
nobody will think you're honest.

218
00:10:01,820 --> 00:10:03,796
Now we're going to look at the hot spots.

219
00:10:03,820 --> 00:10:06,106
Can you tell what's happening
in a conversation?

220
00:10:06,130 --> 00:10:08,796
Can you start to find the hot spots

221
00:10:08,820 --> 00:10:10,796
to see the discrepancies

222
00:10:10,820 --> 00:10:13,011
between someone's words
and someone's actions?

223
00:10:13,035 --> 00:10:14,796
Now, I know it seems really obvious,

224
00:10:14,820 --> 00:10:19,796
but when you're having a conversation
with someone you suspect of deception,

225
00:10:19,820 --> 00:10:22,896
attitude is by far the most overlooked
but telling of indicators.

226
00:10:22,920 --> 00:10:25,116
An honest person
is going to be cooperative.

227
00:10:25,140 --> 00:10:27,188
They're going to show
they're on your side.

228
00:10:27,212 --> 00:10:28,796
They're going to be enthusiastic.

229
00:10:28,820 --> 00:10:32,096
They're going to be willing and helpful
to getting you to the truth.

230
00:10:32,120 --> 00:10:34,896
They're going to be willing
to brainstorm, name suspects,

231
00:10:34,920 --> 00:10:36,196
provide details.

232
00:10:36,220 --> 00:10:37,796
They're going to say,

233
00:10:37,820 --> 00:10:40,996
"Hey, maybe it was those guys in payroll
that forged those checks."

234
00:10:41,020 --> 00:10:44,296
They're going to be infuriated
if they sense they're wrongly accused

235
00:10:44,320 --> 00:10:47,496
throughout the entire course
of the interview, not just in flashes;

236
00:10:47,520 --> 00:10:50,759
they'll be infuriated throughout
the entire course of the interview.

237
00:10:50,783 --> 00:10:52,196
And if you ask someone honest

238
00:10:52,220 --> 00:10:54,796
what should happen
to whomever did forge those checks,

239
00:10:54,820 --> 00:10:56,596
an honest person is much more likely

240
00:10:56,620 --> 00:10:59,796
to recommend strict rather
than lenient punishment.

241
00:10:59,820 --> 00:11:02,487
Now let's say you're having
that exact same conversation

242
00:11:02,511 --> 00:11:03,796
with someone deceptive.

243
00:11:03,820 --> 00:11:05,796
That person may be withdrawn,

244
00:11:05,820 --> 00:11:07,796
look down, lower their voice,

245
00:11:07,820 --> 00:11:09,796
pause, be kind of herky-jerky.

246
00:11:09,820 --> 00:11:11,868
Ask a deceptive person
to tell their story,

247
00:11:11,892 --> 00:11:14,796
they're going to pepper it
with way too much detail

248
00:11:14,820 --> 00:11:17,796
in all kinds of irrelevant places.

249
00:11:17,820 --> 00:11:21,296
And then they're going to tell their story
in strict chronological order.

250
00:11:21,320 --> 00:11:23,096
And what a trained interrogator does

251
00:11:23,120 --> 00:11:26,796
is they come in and in very subtle ways
over the course of several hours,

252
00:11:26,820 --> 00:11:29,796
they will ask that person
to tell that story backwards,

253
00:11:29,820 --> 00:11:31,796
and then they'll watch them squirm,

254
00:11:31,820 --> 00:11:35,249
and track which questions produce
the highest volume of deceptive tells.

255
00:11:35,273 --> 00:11:37,796
Why do they do that?
Well, we all do the same thing.

256
00:11:37,820 --> 00:11:39,796
We rehearse our words,

257
00:11:39,820 --> 00:11:41,796
but we rarely rehearse our gestures.

258
00:11:41,820 --> 00:11:43,796
We say "yes," we shake our heads "no."

259
00:11:43,820 --> 00:11:46,916
We tell very convincing stories,
we slightly shrug our shoulders.

260
00:11:46,940 --> 00:11:48,796
We commit terrible crimes,

261
00:11:48,820 --> 00:11:51,796
and we smile at the delight
in getting away with it.

262
00:11:51,820 --> 00:11:54,796
Now, that smile is known
in the trade as "duping delight."

263
00:11:54,820 --> 00:11:57,796
And we're going to see that
in several videos moving forward,

264
00:11:57,820 --> 00:12:00,896
but we're going to start --
for those of you who don't know him,

265
00:12:00,920 --> 00:12:02,996
this is presidential
candidate John Edwards

266
00:12:03,020 --> 00:12:05,796
who shocked America by fathering
a child out of wedlock.

267
00:12:05,820 --> 00:12:08,796
We're going to see him talk
about getting a paternity test.

268
00:12:08,820 --> 00:12:12,820
See now if you can spot him
saying, "yes" while shaking his head "no,"

269
00:12:12,844 --> 00:12:14,796
slightly shrugging his shoulders.

270
00:12:14,820 --> 00:12:17,496
(Video) John Edwards: I'd be happy
to participate in one.

271
00:12:17,520 --> 00:12:20,396
I know that it's not possible
that this child could be mine,

272
00:12:20,420 --> 00:12:21,996
because of the timing of events.

273
00:12:22,020 --> 00:12:23,796
So I know it's not possible.

274
00:12:23,820 --> 00:12:27,796
Happy to take a paternity test,
and would love to see it happen.

275
00:12:27,820 --> 00:12:30,868
Interviewer: Are you going to do
that soon? Is there somebody --

276
00:12:30,892 --> 00:12:33,796
JE: Well, I'm only one side.
I'm only one side of the test.

277
00:12:33,820 --> 00:12:36,424
But I'm happy to participate in one.

278
00:12:37,615 --> 00:12:40,049
PM: Okay, those head shakes
are much easier to spot

279
00:12:40,073 --> 00:12:41,596
once you know to look for them.

280
00:12:41,620 --> 00:12:45,596
There're going to be times
when someone makes one expression

281
00:12:45,620 --> 00:12:48,796
while masking another that just
kind of leaks through in a flash.

282
00:12:48,820 --> 00:12:50,796
Murderers are known to leak sadness.

283
00:12:50,820 --> 00:12:53,396
Your new joint venture partner
might shake your hand,

284
00:12:53,420 --> 00:12:57,796
celebrate, go out to dinner with you
and then leak an expression of anger.

285
00:12:57,820 --> 00:13:01,396
And we're not all going to become
facial expression experts overnight here,

286
00:13:01,420 --> 00:13:03,898
but there's one I can teach you
that's very dangerous

287
00:13:03,922 --> 00:13:05,135
and it's easy to learn,

288
00:13:05,159 --> 00:13:06,996
and that's the expression of contempt.

289
00:13:07,020 --> 00:13:10,020
Now with anger, you've got
two people on an even playing field.

290
00:13:10,044 --> 00:13:12,235
It's still somewhat
of a healthy relationship.

291
00:13:12,259 --> 00:13:15,796
But when anger turns to contempt,
you've been dismissed.

292
00:13:15,820 --> 00:13:17,796
It's associated with moral superiority.

293
00:13:17,820 --> 00:13:20,796
And for that reason, it's very,
very hard to recover from.

294
00:13:20,820 --> 00:13:22,796
Here's what it looks like.

295
00:13:22,820 --> 00:13:26,796
It's marked by one lip corner
pulled up and in.

296
00:13:26,820 --> 00:13:29,796
It's the only asymmetrical expression.

297
00:13:29,820 --> 00:13:33,796
And in the presence of contempt,
whether or not deception follows --

298
00:13:33,820 --> 00:13:35,796
and it doesn't always follow --

299
00:13:35,820 --> 00:13:37,868
look the other way,
go the other direction,

300
00:13:37,892 --> 00:13:39,796
reconsider the deal,

301
00:13:39,820 --> 00:13:43,796
say, "No thank you. I'm not coming up
for just one more nightcap. Thank you."

302
00:13:43,820 --> 00:13:47,796
Science has surfaced
many, many more indicators.

303
00:13:47,820 --> 00:13:49,796
We know, for example,

304
00:13:49,820 --> 00:13:51,820
we know liars will shift their blink rate,

305
00:13:51,844 --> 00:13:53,796
point their feet towards an exit.

306
00:13:53,820 --> 00:13:55,796
They will take barrier objects

307
00:13:55,820 --> 00:13:59,249
and put them between themselves
and the person that is interviewing them.

308
00:13:59,273 --> 00:14:00,796
They'll alter their vocal tone,

309
00:14:00,820 --> 00:14:03,796
often making their vocal tone much lower.

310
00:14:03,820 --> 00:14:05,796
Now here's the deal.

311
00:14:05,820 --> 00:14:08,796
These behaviors are just behaviors.

312
00:14:08,820 --> 00:14:10,796
They're not proof of deception.

313
00:14:10,820 --> 00:14:12,796
They're red flags.

314
00:14:12,820 --> 00:14:14,796
We're human beings.

315
00:14:14,820 --> 00:14:18,096
We make deceptive flailing gestures
all over the place all day long.

316
00:14:18,120 --> 00:14:20,311
They don't mean anything
in and of themselves.

317
00:14:20,335 --> 00:14:22,896
But when you see clusters
of them, that's your signal.

318
00:14:22,920 --> 00:14:25,796
Look, listen, probe,
ask some hard questions,

319
00:14:25,820 --> 00:14:28,796
get out of that very comfortable
mode of knowing,

320
00:14:28,820 --> 00:14:31,796
walk into curiosity mode,
ask more questions,

321
00:14:31,820 --> 00:14:35,196
have a little dignity, treat the person
you're talking to with rapport.

322
00:14:35,220 --> 00:14:38,796
Don't try to be like those folks
on "Law & Order" and those other TV shows

323
00:14:38,820 --> 00:14:40,868
that pummel their subjects
into submission.

324
00:14:40,892 --> 00:14:42,896
Don't be too aggressive, it doesn't work.

325
00:14:43,939 --> 00:14:47,296
Now, we've talked a little bit
about how to talk to someone who's lying

326
00:14:47,320 --> 00:14:48,796
and how to spot a lie.

327
00:14:48,820 --> 00:14:52,296
And as I promised, we're now going
to look at what the truth looks like.

328
00:14:52,320 --> 00:14:54,096
But I'm going to show you two videos,

329
00:14:54,120 --> 00:14:56,796
two mothers -- one is lying,
one is telling the truth.

330
00:14:56,820 --> 00:15:00,916
And these were surfaced by researcher
David Matsumoto in California.

331
00:15:00,940 --> 00:15:04,796
And I think they're an excellent example
of what the truth looks like.

332
00:15:04,820 --> 00:15:06,796
This mother, Diane Downs,

333
00:15:06,820 --> 00:15:08,796
shot her kids at close range,

334
00:15:08,820 --> 00:15:12,796
drove them to the hospital
while they bled all over the car,

335
00:15:12,820 --> 00:15:14,796
claimed a scraggy-haired stranger did it.

336
00:15:14,820 --> 00:15:16,796
And you'll see when you see the video,

337
00:15:16,820 --> 00:15:19,154
she can't even pretend
to be an agonizing mother.

338
00:15:19,178 --> 00:15:22,796
What you want to look for here
is an incredible discrepancy

339
00:15:22,820 --> 00:15:26,796
between horrific events that she describes
and her very, very cool demeanor.

340
00:15:26,820 --> 00:15:30,296
And if you look closely, you'll see
duping delight throughout this video.

341
00:15:30,320 --> 00:15:32,796
(Video) Diane Downs:
At night when I close my eyes,

342
00:15:32,820 --> 00:15:35,916
I can see Christie reaching
her hand out to me while I'm driving,

343
00:15:35,940 --> 00:15:38,196
and the blood just kept
coming out of her mouth.

344
00:15:38,220 --> 00:15:40,363
And that -- maybe
it'll fade too with time --

345
00:15:40,387 --> 00:15:41,796
but I don't think so.

346
00:15:41,820 --> 00:15:44,820
That bothers me the most.

347
00:15:51,820 --> 00:15:53,796
PM: Now I'm going to show you a video

348
00:15:53,820 --> 00:15:55,868
of an actual grieving mother,
Erin Runnion,

349
00:15:55,892 --> 00:15:59,796
confronting her daughter's murderer
and torturer in court.

350
00:15:59,820 --> 00:16:01,820
Here you're going to see no false emotion,

351
00:16:01,844 --> 00:16:04,796
just the authentic expression
of a mother's agony.

352
00:16:04,820 --> 00:16:06,911
(Video) Erin Runnion:
I wrote this statement

353
00:16:06,935 --> 00:16:09,596
on the third anniversary
of the night you took my baby,

354
00:16:09,620 --> 00:16:10,896
and you hurt her,

355
00:16:10,920 --> 00:16:12,796
and you crushed her,

356
00:16:12,820 --> 00:16:16,796
you terrified her until her heart stopped.

357
00:16:16,820 --> 00:16:19,796
And she fought, and I know she fought you.

358
00:16:19,820 --> 00:16:23,796
But I know she looked at you
with those amazing brown eyes,

359
00:16:23,820 --> 00:16:26,796
and you still wanted to kill her.

360
00:16:26,820 --> 00:16:28,796
And I don't understand it,

361
00:16:28,820 --> 00:16:30,367
and I never will.

362
00:16:32,470 --> 00:16:35,796
PM: Okay, there's no doubting
the veracity of those emotions.

363
00:16:35,820 --> 00:16:38,796
Now the technology
around what the truth looks like

364
00:16:38,820 --> 00:16:41,796
is progressing on, the science of it.

365
00:16:41,820 --> 00:16:43,796
We know, for example,

366
00:16:43,820 --> 00:16:46,963
that we now have specialized eye trackers
and infrared brain scans,

367
00:16:46,987 --> 00:16:49,796
MRI's that can decode the signals
that our bodies send out

368
00:16:49,820 --> 00:16:51,796
when we're trying to be deceptive.

369
00:16:51,820 --> 00:16:54,796
And these technologies are going
to be marketed to all of us

370
00:16:54,820 --> 00:16:56,796
as panaceas for deceit,

371
00:16:56,820 --> 00:16:59,796
and they will prove
incredibly useful some day.

372
00:16:59,820 --> 00:17:02,059
But you've got to ask yourself
in the meantime:

373
00:17:02,083 --> 00:17:04,179
Who do you want on your side
of the meeting,

374
00:17:04,203 --> 00:17:06,796
someone who's trained
in getting to the truth

375
00:17:06,820 --> 00:17:09,896
or some guy who's going to drag
a 400-pound electroencephalogram

376
00:17:09,920 --> 00:17:11,196
through the door?

377
00:17:11,220 --> 00:17:14,796
Liespotters rely on human tools.

378
00:17:14,820 --> 00:17:16,796
They know, as someone once said,

379
00:17:16,820 --> 00:17:18,796
"Character's who you are in the dark."

380
00:17:18,820 --> 00:17:22,796
And what's kind of interesting
is that today, we have so little darkness.

381
00:17:22,820 --> 00:17:25,796
Our world is lit up 24 hours a day.

382
00:17:25,820 --> 00:17:29,796
It's transparent
with blogs and social networks

383
00:17:29,820 --> 00:17:32,496
broadcasting the buzz
of a whole new generation of people

384
00:17:32,520 --> 00:17:35,096
that have made a choice to live
their lives in public.

385
00:17:35,120 --> 00:17:38,796
It's a much more noisy world.

386
00:17:38,820 --> 00:17:42,796
So one challenge we have is to remember,

387
00:17:42,820 --> 00:17:45,796
oversharing, that's not honesty.

388
00:17:45,820 --> 00:17:49,796
Our manic tweeting and texting
can blind us

389
00:17:49,820 --> 00:17:53,396
to the fact that the subtleties
of human decency -- character integrity --

390
00:17:53,420 --> 00:17:56,468
that's still what matters,
that's always what's going to matter.

391
00:17:56,492 --> 00:17:57,996
So in this much noisier world,

392
00:17:58,020 --> 00:17:59,796
it might make sense for us

393
00:17:59,820 --> 00:18:04,796
to be just a little bit more explicit
about our moral code.

394
00:18:04,820 --> 00:18:07,396
When you combine the science
of recognizing deception

395
00:18:07,420 --> 00:18:09,096
with the art of looking, listening,

396
00:18:09,120 --> 00:18:11,796
you exempt yourself
from collaborating in a lie.

397
00:18:11,820 --> 00:18:15,796
You start up that path
of being just a little bit more explicit,

398
00:18:15,820 --> 00:18:17,820
because you signal to everyone around you,

399
00:18:17,844 --> 00:18:22,796
you say, "Hey, my world, our world,
it's going to be an honest one.

400
00:18:22,820 --> 00:18:25,440
My world is going to be
one where truth is strengthened

401
00:18:25,464 --> 00:18:27,796
and falsehood is recognized
and marginalized."

402
00:18:27,820 --> 00:18:29,796
And when you do that,

403
00:18:29,820 --> 00:18:32,796
the ground around you starts
to shift just a little bit.

404
00:18:32,820 --> 00:18:35,796
And that's the truth. Thank you.

405
00:18:35,820 --> 00:18:40,820
(Applause)

