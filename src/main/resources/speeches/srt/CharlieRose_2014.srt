1
00:00:13,201 --> 00:00:16,827
Charlie Rose: So Larry sent me an email

2
00:00:16,827 --> 00:00:18,814
and he basically said,

3
00:00:18,814 --> 00:00:22,543
we've got to make sure that 
we don't seem like we're

4
00:00:22,543 --> 00:00:27,034
a couple of middle-aged boring men.

5
00:00:27,034 --> 00:00:30,076
I said, I'm flattered by that --

6
00:00:30,076 --> 00:00:32,448
(Laughter) —

7
00:00:32,448 --> 00:00:35,963
because I'm a bit older,

8
00:00:35,963 --> 00:00:40,114
and he has a bit more net worth than I do.

9
00:00:40,114 --> 00:00:42,713
Larry Page: Well, thank you.

10
00:00:42,713 --> 00:00:45,693
CR: So we'll have a conversation about

11
00:00:45,693 --> 00:00:48,391
the Internet, and we'll have a conversation Google,

12
00:00:48,391 --> 00:00:49,825
and we'll have a conversation about search

13
00:00:49,825 --> 00:00:51,192
and privacy,

14
00:00:51,192 --> 00:00:52,747
and also about your philosophy

15
00:00:52,747 --> 00:00:55,203
and a sense of how you've connected the dots

16
00:00:55,203 --> 00:00:57,294
and how this journey that began

17
00:00:57,294 --> 00:00:58,578
some time ago

18
00:00:58,578 --> 00:01:00,473
has such interesting prospects.

19
00:01:00,473 --> 00:01:03,069
Mainly we want to talk about the future.

20
00:01:03,069 --> 00:01:04,658
So my first question: Where is Google

21
00:01:04,658 --> 00:01:06,704
and where is it going?

22
00:01:06,704 --> 00:01:08,163
LP: Well, this is something we think about a lot,

23
00:01:08,163 --> 00:01:11,738
and our mission we defined a long time ago

24
00:01:11,738 --> 00:01:14,001
is to organize the world's information

25
00:01:14,001 --> 00:01:17,439
and make it universally accessible and useful.

26
00:01:17,439 --> 00:01:19,481
And people always say,

27
00:01:19,481 --> 00:01:21,696
is that really what you guys are still doing?

28
00:01:21,696 --> 00:01:23,814
And I always kind of think about that myself,

29
00:01:23,814 --> 00:01:26,010
and I'm not quite sure.

30
00:01:26,010 --> 00:01:30,017
But actually, when I think about search,

31
00:01:30,017 --> 00:01:32,633
it's such a deep thing for all of us,

32
00:01:32,633 --> 00:01:34,876
to really understand what you want,

33
00:01:34,876 --> 00:01:37,244
to understand the world's information,

34
00:01:37,244 --> 00:01:40,776
and we're still very much in the early stages of that,

35
00:01:40,776 --> 00:01:42,589
which is totally crazy.

36
00:01:42,589 --> 00:01:45,107
We've been at it for 15 years already,

37
00:01:45,107 --> 00:01:48,682
but it's not at all done.

38
00:01:48,682 --> 00:01:51,358
CR: When it's done, how will it be?

39
00:01:51,358 --> 00:01:54,075
LP: Well, I guess,

40
00:01:54,075 --> 00:01:56,475
in thinking about where we're going --

41
00:01:56,475 --> 00:01:58,762
you know, why is it not done? --

42
00:01:58,762 --> 00:02:01,198
a lot of it is just computing's kind of a mess.

43
00:02:01,198 --> 00:02:03,001
You know, your computer
doesn't know where you are,

44
00:02:03,001 --> 00:02:05,036
it doesn't know what you're doing,

45
00:02:05,036 --> 00:02:06,718
it doesn't know what you know,

46
00:02:06,718 --> 00:02:09,294
and a lot we've been trying to do recently

47
00:02:09,294 --> 00:02:12,589
is just make your devices work,

48
00:02:12,589 --> 00:02:14,930
make them understand your context.

49
00:02:14,930 --> 00:02:16,933
Google Now, you know, knows where you are,

50
00:02:16,933 --> 00:02:19,115
knows what you may need.

51
00:02:19,115 --> 00:02:23,223
So really having computing 
work and understand you

52
00:02:23,223 --> 00:02:25,279
and understand that information,

53
00:02:25,279 --> 00:02:27,589
we really haven't done that yet.

54
00:02:27,589 --> 00:02:29,138
It's still very, very clunky.

55
00:02:29,138 --> 00:02:31,504
CR: Tell me, when you look at what Google is doing,

56
00:02:31,504 --> 00:02:34,473
where does Deep Mind fit?

57
00:02:34,473 --> 00:02:36,057
LP: Yeah, so Deep Mind is a company

58
00:02:36,057 --> 00:02:38,588
we just acquired recently.

59
00:02:38,588 --> 00:02:41,670
It's in the U.K.

60
00:02:41,670 --> 00:02:44,324
First, let me tell you the way we got there,

61
00:02:44,324 --> 00:02:46,552
which was looking at search

62
00:02:46,552 --> 00:02:48,175
and really understanding,

63
00:02:48,175 --> 00:02:50,408
trying to understand everything,

64
00:02:50,408 --> 00:02:52,013
and also make the computers not clunky

65
00:02:52,013 --> 00:02:54,214
and really understand you --

66
00:02:54,214 --> 00:02:56,326
like, voice was really important.

67
00:02:56,326 --> 00:02:59,187
So what's the state of the art 
on speech recognition?

68
00:02:59,187 --> 00:03:00,847
It's not very good.

69
00:03:00,847 --> 00:03:02,913
It doesn't really understand you.

70
00:03:02,913 --> 00:03:04,916
So we started doing machine learning research

71
00:03:04,916 --> 00:03:06,453
to improve that.

72
00:03:06,453 --> 00:03:08,156
That helped a lot.

73
00:03:08,156 --> 00:03:10,523
And we started just looking at things like YouTube.

74
00:03:10,523 --> 00:03:12,491
Can we understand YouTube?

75
00:03:12,491 --> 00:03:15,177
But we actually ran machine learning on YouTube

76
00:03:15,177 --> 00:03:19,262
and it discovered cats, just by itself.

77
00:03:19,262 --> 00:03:21,353
Now, that's an important concept.

78
00:03:21,353 --> 00:03:24,344
And we realized there's really something here.

79
00:03:24,344 --> 00:03:26,461
If we can learn what cats are,

80
00:03:26,461 --> 00:03:28,536
that must be really important.

81
00:03:28,536 --> 00:03:31,165
So I think Deep Mind,

82
00:03:31,165 --> 00:03:33,529
what's really amazing about Deep Mind

83
00:03:33,529 --> 00:03:35,533
is that it can actually --

84
00:03:35,533 --> 00:03:39,090
they're learning things in this unsupervised way.

85
00:03:39,090 --> 00:03:41,657
They started with video games,

86
00:03:41,657 --> 00:03:44,150
and really just, maybe I can show the video,

87
00:03:44,150 --> 00:03:46,354
just playing video games,

88
00:03:46,354 --> 00:03:48,369
and learning how to do that automatically.

89
00:03:48,369 --> 00:03:50,221
CR: Take a look at the video games

90
00:03:50,221 --> 00:03:52,631
and how machines are coming to be able

91
00:03:52,631 --> 00:03:55,087
to do some remarkable things.

92
00:03:55,087 --> 00:03:56,416
LP: The amazing thing about this

93
00:03:56,416 --> 00:03:58,096
is this is, I mean, obviously,

94
00:03:58,096 --> 00:03:59,570
these are old games,

95
00:03:59,570 --> 00:04:04,368
but the system just sees what you see, the pixels,

96
00:04:04,368 --> 00:04:06,799
and it has the controls and it has the score,

97
00:04:06,799 --> 00:04:09,010
and it's learned to play all of these games,

98
00:04:09,010 --> 00:04:10,589
same program.

99
00:04:10,589 --> 00:04:12,626
It's learned to play all of these games

100
00:04:12,626 --> 00:04:14,412
with superhuman performance.

101
00:04:14,412 --> 00:04:16,267
We've not been able to do things like this

102
00:04:16,267 --> 00:04:17,785
with computers before.

103
00:04:17,785 --> 00:04:20,080
And maybe I'll just narrate this one quickly.

104
00:04:20,080 --> 00:04:22,885
This is boxing, and it figures out it can

105
00:04:22,885 --> 00:04:25,519
sort of pin the opponent down.

106
00:04:25,519 --> 00:04:27,258
The computer's on the left,

107
00:04:27,258 --> 00:04:30,343
and it's just racking up points.

108
00:04:30,343 --> 00:04:32,429
So imagine if this kind

109
00:04:32,429 --> 00:04:34,556
of intelligence were thrown at your schedule,

110
00:04:34,556 --> 00:04:39,193
or your information needs, or things like that.

111
00:04:39,193 --> 00:04:41,811
We're really just at the beginning of that,

112
00:04:41,811 --> 00:04:44,176
and that's what I'm really excited about.

113
00:04:44,176 --> 00:04:46,646
CR: When you look at all that's taken place

114
00:04:46,646 --> 00:04:49,230
with Deep Mind and the boxing,

115
00:04:49,230 --> 00:04:51,570
also a part of where we're going

116
00:04:51,570 --> 00:04:54,459
is artificial intelligence.

117
00:04:54,459 --> 00:04:57,258
Where are we, when you look at that?

118
00:04:57,258 --> 00:04:59,043
LP: Well, I think for me,

119
00:04:59,043 --> 00:05:00,546
this is kind of one of the most exciting things

120
00:05:00,546 --> 00:05:02,458
I've seen in a long time.

121
00:05:02,458 --> 00:05:04,871
The guy who started this company, Demis,

122
00:05:04,871 --> 00:05:07,649
has a neuroscience and a
computer science background.

123
00:05:07,649 --> 00:05:09,279
He went back to school

124
00:05:09,279 --> 00:05:12,405
to get his Ph.D. to study the brain.

125
00:05:12,405 --> 00:05:15,025
And so I think we're seeing a lot of exciting work

126
00:05:15,025 --> 00:05:18,106
going on that sort of crosses computer science

127
00:05:18,106 --> 00:05:19,856
and neuroscience

128
00:05:19,856 --> 00:05:22,181
in terms of really understanding

129
00:05:22,181 --> 00:05:24,635
what it takes to make something smart

130
00:05:24,635 --> 00:05:26,350
and do really interesting things.

131
00:05:26,350 --> 00:05:28,488
CR: But where's the level of it now?

132
00:05:28,488 --> 00:05:31,194
And how fast do you think we are moving?

133
00:05:31,194 --> 00:05:34,463
LP: Well, this is the state of the art right now,

134
00:05:34,463 --> 00:05:36,594
understanding cats on YouTube

135
00:05:36,594 --> 00:05:37,877
and things like that,

136
00:05:37,877 --> 00:05:40,024
improving voice recognition.

137
00:05:40,024 --> 00:05:42,442
We used a lot of machine learning

138
00:05:42,442 --> 00:05:44,921
to improve things incrementally,

139
00:05:44,921 --> 00:05:48,315
but I think for me, this example's really exciting,

140
00:05:48,315 --> 00:05:50,558
because it's one program

141
00:05:50,558 --> 00:05:52,602
that can do a lot of different things.

142
00:05:52,602 --> 00:05:53,740
CR: I don't know if we can do this,

143
00:05:53,740 --> 00:05:54,925
but we've got the image of the cat.

144
00:05:54,925 --> 00:05:56,679
It would be wonderful to see this.

145
00:05:56,679 --> 00:05:59,188
This is how machines looked at cats

146
00:05:59,188 --> 00:06:00,303
and what they came up with.

147
00:06:00,303 --> 00:06:01,358
Can we see that image?

148
00:06:01,358 --> 00:06:03,760
LP: Yeah.
CR: There it is. Can you see the cat?

149
00:06:03,760 --> 00:06:05,787
Designed by machines, seen by machines.

150
00:06:05,787 --> 00:06:06,897
LP: That's right.

151
00:06:06,897 --> 00:06:09,504
So this is learned from just watching YouTube.

152
00:06:09,504 --> 00:06:11,371
And there's no training,

153
00:06:11,371 --> 00:06:12,755
no notion of a cat,

154
00:06:12,755 --> 00:06:15,316
but this concept of a cat

155
00:06:15,316 --> 00:06:18,124
is something important that you would understand,

156
00:06:18,124 --> 00:06:20,647
and now that the machines can kind of understand.

157
00:06:20,647 --> 00:06:21,819
Maybe just finishing

158
00:06:21,819 --> 00:06:24,041
also on the search part,

159
00:06:24,041 --> 00:06:26,827
it started with search, really understanding

160
00:06:26,827 --> 00:06:29,391
people's context and their information.

161
00:06:29,391 --> 00:06:31,251
I did have a video

162
00:06:31,251 --> 00:06:33,261
I wanted to show quickly on that

163
00:06:33,261 --> 00:06:34,908
that we actually found.

164
00:06:34,908 --> 00:06:40,020
(Video) ["Soy, Kenya"]

165
00:06:40,400 --> 00:06:42,272
Zack Matere: Not long ago,

166
00:06:42,272 --> 00:06:44,858
I planted a crop of potatoes.

167
00:06:44,858 --> 00:06:48,258
Then suddenly they started
dying one after the other.

168
00:06:48,258 --> 00:06:51,008
I checked out the books and 
they didn't tell me much.

169
00:06:51,008 --> 00:06:52,954
So, I went and I did a search.

170
00:06:52,954 --> 00:06:56,073
["Zack Matere, Farmer"]

171
00:06:57,429 --> 00:07:00,576
Potato diseases.

172
00:07:00,576 --> 00:07:02,304
One of the websites told me

173
00:07:02,304 --> 00:07:04,206
that ants could be the problem.

174
00:07:04,206 --> 00:07:06,477
It said, sprinkle wood ash over the plants.

175
00:07:06,477 --> 00:07:08,761
Then after a few days the ants disappeared.

176
00:07:08,761 --> 00:07:11,355
I got excited about the Internet.

177
00:07:11,355 --> 00:07:13,020
I have this friend

178
00:07:13,020 --> 00:07:16,638
who really would like to expand his business.

179
00:07:16,638 --> 00:07:19,833
So I went with him to the cyber cafe

180
00:07:19,833 --> 00:07:22,374
and we checked out several sites.

181
00:07:22,374 --> 00:07:24,915
When I met him next, he was going to put a windmill

182
00:07:24,915 --> 00:07:27,609
at the local school.

183
00:07:27,609 --> 00:07:29,213
I felt proud because

184
00:07:29,213 --> 00:07:31,241
something that wasn't there before

185
00:07:31,241 --> 00:07:33,128
was suddenly there.

186
00:07:33,128 --> 00:07:35,818
I realized that not everybody

187
00:07:35,818 --> 00:07:37,352
can be able to access

188
00:07:37,352 --> 00:07:38,838
what I was able to access.

189
00:07:38,838 --> 00:07:40,676
I thought that I need to have an Internet

190
00:07:40,676 --> 00:07:42,477
that my grandmother can use.

191
00:07:42,477 --> 00:07:44,934
So I thought about a notice board.

192
00:07:44,934 --> 00:07:46,850
A simple wooden notice board.

193
00:07:46,850 --> 00:07:49,165
When I get information on my phone,

194
00:07:49,165 --> 00:07:51,402
I'm able to post the information

195
00:07:51,402 --> 00:07:53,124
on the notice board.

196
00:07:53,124 --> 00:07:55,982
So it's basically like a computer.

197
00:07:55,982 --> 00:07:59,871
I use the Internet to help people.

198
00:07:59,871 --> 00:08:03,281
I think I am searching for

199
00:08:03,281 --> 00:08:04,822
a better life

200
00:08:04,822 --> 00:08:08,936
for me and my neighbors.

201
00:08:08,936 --> 00:08:12,920
So many people have access to information,

202
00:08:12,920 --> 00:08:15,501
but there's no follow-up to that.

203
00:08:15,501 --> 00:08:18,009
I think the follow-up to that is our knowledge.

204
00:08:18,009 --> 00:08:19,615
When people have the knowledge,

205
00:08:19,615 --> 00:08:21,245
they can find solutions

206
00:08:21,245 --> 00:08:23,229
without having to helped out.

207
00:08:23,260 --> 00:08:25,381
Information is powerful,

208
00:08:25,381 --> 00:08:29,983
but it is how we use it that will define us.

209
00:08:29,983 --> 00:08:34,364
(Applause)

210
00:08:34,364 --> 00:08:36,910
LP: Now, the amazing thing about that video,

211
00:08:36,910 --> 00:08:38,376
actually, was we just read about it in the news,

212
00:08:38,376 --> 00:08:40,881
and we found this gentlemen,

213
00:08:40,881 --> 00:08:43,196
and made that little clip.

214
00:08:43,196 --> 00:08:44,587
CR: When I talk to people about you,

215
00:08:44,587 --> 00:08:47,192
they say to me, people who know you well, say,

216
00:08:47,192 --> 00:08:49,083
Larry wants to change the world,

217
00:08:49,083 --> 00:08:53,195
and he believes technology can show the way.

218
00:08:53,195 --> 00:08:55,053
And that means access to the Internet.

219
00:08:55,053 --> 00:08:56,784
It has to do with languages.

220
00:08:56,784 --> 00:08:59,613
It also means how people can get access

221
00:08:59,613 --> 00:09:02,319
and do things that will affect their community,

222
00:09:02,319 --> 00:09:04,812
and this is an example.

223
00:09:04,812 --> 00:09:08,388
LP: Yeah, that's right, and I think for me,

224
00:09:08,388 --> 00:09:10,770
I have been focusing on access more,

225
00:09:10,770 --> 00:09:12,968
if we're talking about the future.

226
00:09:12,968 --> 00:09:15,642
We recently released this Loon Project

227
00:09:15,642 --> 00:09:17,942
which is using balloons to do it.

228
00:09:17,942 --> 00:09:19,602
It sounds totally crazy.

229
00:09:19,602 --> 00:09:22,141
We can show the video here.

230
00:09:22,141 --> 00:09:23,621
Actually, two out of three people in the world

231
00:09:23,621 --> 00:09:26,007
don't have good Internet access now.

232
00:09:26,007 --> 00:09:28,913
We actually think this can really help people

233
00:09:28,913 --> 00:09:30,970
sort of cost-efficiently.

234
00:09:30,970 --> 00:09:34,341
CR: It's a balloon.
LP: Yeah, get access to the Internet.

235
00:09:34,341 --> 00:09:36,484
CR: And why does this balloon give you access

236
00:09:36,484 --> 00:09:37,697
to the Internet?

237
00:09:37,697 --> 00:09:38,912
Because there was some interesting things

238
00:09:38,912 --> 00:09:40,746
you had to do to figure out how

239
00:09:40,746 --> 00:09:42,877
to make balloons possible,

240
00:09:42,877 --> 00:09:44,626
they didn't have to be tethered.

241
00:09:44,626 --> 00:09:46,707
LP: Yeah, and this is a good example of innovation.

242
00:09:46,707 --> 00:09:49,251
Like, we've been thinking about this idea

243
00:09:49,251 --> 00:09:51,023
for five years or more

244
00:09:51,023 --> 00:09:52,624
before we started working on it,

245
00:09:52,624 --> 00:09:53,943
but it was just really,

246
00:09:53,943 --> 00:09:57,463
how do we get access points up high, cheaply?

247
00:09:57,463 --> 00:09:59,255
You normally have to use satellites

248
00:09:59,255 --> 00:10:02,194
and it takes a long time to launch them.

249
00:10:02,194 --> 00:10:04,688
But you saw there how easy it is to launch a balloon

250
00:10:04,688 --> 00:10:06,207
and get it up,

251
00:10:06,207 --> 00:10:08,208
and actually again, it's the power of the Internet,

252
00:10:08,208 --> 00:10:09,988
I did a search on it,

253
00:10:09,988 --> 00:10:12,292
and I found, 30, 40 years ago,

254
00:10:12,292 --> 00:10:14,181
someone had put up a balloon

255
00:10:14,181 --> 00:10:16,986
and it had gone around the Earth multiple times.

256
00:10:16,986 --> 00:10:19,821
And I thought, why can't we do that today?

257
00:10:19,821 --> 00:10:22,188
And that's how this project got going.

258
00:10:22,188 --> 00:10:24,518
CR: But are you at the mercy of the wind?

259
00:10:24,518 --> 00:10:26,640
LP: Yeah, but it turns out,

260
00:10:26,640 --> 00:10:28,133
we did some weather simulations

261
00:10:28,133 --> 00:10:30,680
which probably hadn't really been done before,

262
00:10:30,680 --> 00:10:32,790
and if you control the altitude of the balloons,

263
00:10:32,790 --> 00:10:35,071
which you can do by pumping air into them

264
00:10:35,071 --> 00:10:36,893
and other ways,

265
00:10:36,893 --> 00:10:39,822
you can actually control roughly where they go,

266
00:10:39,822 --> 00:10:42,027
and so I think we can build a worldwide mesh

267
00:10:42,027 --> 00:10:45,366
of these balloons that can cover the whole planet.

268
00:10:45,366 --> 00:10:47,608
CR: Before I talk about the future and transportation,

269
00:10:47,608 --> 00:10:49,503
where you've been a nerd for a while,

270
00:10:49,503 --> 00:10:51,927
and this fascination you have with transportation

271
00:10:51,927 --> 00:10:53,990
and automated cars and bicycles,

272
00:10:53,990 --> 00:10:55,727
let me talk a bit about what's been the subject here

273
00:10:55,727 --> 00:10:58,170
earlier with Edward Snowden.

274
00:10:58,170 --> 00:11:01,276
It is security and privacy.

275
00:11:01,276 --> 00:11:03,616
You have to have been thinking about that.

276
00:11:03,616 --> 00:11:04,970
LP: Yeah, absolutely.

277
00:11:04,970 --> 00:11:07,813
I saw the picture of Sergey with
Edward Snowden yesterday.

278
00:11:07,813 --> 00:11:10,683
Some of you may have seen it.

279
00:11:10,683 --> 00:11:13,854
But I think, for me, I guess,

280
00:11:13,854 --> 00:11:17,516
privacy and security are a really important thing.

281
00:11:17,516 --> 00:11:19,761
We think about it in terms of both things,

282
00:11:19,761 --> 00:11:22,664
and I think you can't have privacy without security,

283
00:11:22,664 --> 00:11:25,035
so let me just talk about security first,

284
00:11:25,035 --> 00:11:27,631
because you asked about Snowden and all of that,

285
00:11:27,631 --> 00:11:30,072
and then I'll say a little bit about privacy.

286
00:11:30,072 --> 00:11:33,872
I think for me, it's tremendously disappointing

287
00:11:33,872 --> 00:11:35,311
that the government

288
00:11:35,311 --> 00:11:37,641
secretly did all this stuff and didn't tell us.

289
00:11:37,641 --> 00:11:40,944
I don't think we can have a democracy

290
00:11:40,944 --> 00:11:44,374
if we're having to protect you and our users

291
00:11:44,374 --> 00:11:46,070
from the government

292
00:11:46,070 --> 00:11:48,873
for stuff that we've never had a conversation about.

293
00:11:48,873 --> 00:11:50,769
And I don't mean we have to know

294
00:11:50,769 --> 00:11:52,464
what the particular terrorist attack is they're worried

295
00:11:52,464 --> 00:11:54,226
about protecting us from,

296
00:11:54,226 --> 00:11:56,024
but we do need to know

297
00:11:56,024 --> 00:11:58,434
what the parameters of it is,

298
00:11:58,434 --> 00:12:00,478
what kind of surveillance the government's

299
00:12:00,478 --> 00:12:02,646
going to do and how and why,

300
00:12:02,646 --> 00:12:04,923
and I think we haven't had that conversation.

301
00:12:04,923 --> 00:12:07,490
So I think the government's actually done

302
00:12:07,490 --> 00:12:09,658
itself a tremendous disservice

303
00:12:09,658 --> 00:12:11,819
by doing all that in secret.

304
00:12:11,819 --> 00:12:13,434
CR: Never coming to Google

305
00:12:13,434 --> 00:12:14,959
to ask for anything.

306
00:12:14,959 --> 00:12:16,989
LP: Not Google, but the public.

307
00:12:16,989 --> 00:12:20,762
I think we need to 
have a debate about that,

308
00:12:20,762 --> 00:12:23,261
or we can't have a functioning democracy.

309
00:12:23,261 --> 00:12:24,667
It's just not possible.

310
00:12:24,667 --> 00:12:26,911
So I'm sad that Google's

311
00:12:26,911 --> 00:12:29,527
in the position of protecting you and our users

312
00:12:29,527 --> 00:12:31,061
from the government

313
00:12:31,061 --> 00:12:33,305
doing secret thing that nobody knows about.

314
00:12:33,305 --> 00:12:35,052
It doesn't make any sense.

315
00:12:35,052 --> 00:12:38,042
CR: Yeah. And then there's a privacy side of it.

316
00:12:38,042 --> 00:12:40,469
LP: Yes. The privacy side,

317
00:12:40,469 --> 00:12:42,438
I think it's -- the world is changing.

318
00:12:42,438 --> 00:12:46,343
You carry a phone. It knows where you are.

319
00:12:46,343 --> 00:12:49,428
There's so much more information about you,

320
00:12:49,428 --> 00:12:52,274
and that's an important thing,

321
00:12:52,274 --> 00:12:54,546
and it makes sense why people are asking

322
00:12:54,546 --> 00:12:56,582
difficult questions.

323
00:12:56,582 --> 00:12:59,949
We spend a lot of time thinking about this

324
00:12:59,949 --> 00:13:02,660
and what the issues are.

325
00:13:02,660 --> 00:13:04,389
I'm a little bit --

326
00:13:04,389 --> 00:13:05,649
I think the main thing that we need to do

327
00:13:05,649 --> 00:13:08,011
is just provide people choice,

328
00:13:08,011 --> 00:13:10,523
show them what data's being collected --

329
00:13:10,523 --> 00:13:15,274
search history, location data.

330
00:13:15,274 --> 00:13:18,046
We're excited about incognito mode in Chrome,

331
00:13:18,046 --> 00:13:20,295
and doing that in more ways,

332
00:13:20,295 --> 00:13:21,691
just giving people more choice

333
00:13:21,691 --> 00:13:24,984
and more awareness of what's going on.

334
00:13:24,984 --> 00:13:27,377
I also think it's very easy.

335
00:13:27,377 --> 00:13:28,654
What I'm worried is that we throw out

336
00:13:28,654 --> 00:13:30,744
the baby with the bathwater.

337
00:13:30,744 --> 00:13:33,658
And I look at, on your show, actually,

338
00:13:33,658 --> 00:13:35,377
I kind of lost my voice,

339
00:13:35,377 --> 00:13:36,708
and I haven't gotten it back.

340
00:13:36,708 --> 00:13:38,352
I'm hoping that by talking to you

341
00:13:38,352 --> 00:13:40,005
I'm going to get it back.

342
00:13:40,005 --> 00:13:41,737
CR: If I could do anything, I would do that.

343
00:13:41,737 --> 00:13:43,917
LP: All right. So get out your voodoo doll

344
00:13:43,917 --> 00:13:46,336
and whatever you need to do.

345
00:13:46,336 --> 00:13:48,664
But I think, you know what, I look at that,

346
00:13:48,664 --> 00:13:50,494
I made that public,

347
00:13:50,494 --> 00:13:51,711
and I got all this information.

348
00:13:51,711 --> 00:13:54,440
We got a survey done on medical conditions

349
00:13:54,440 --> 00:13:57,811
with people who have similar issues,

350
00:13:57,811 --> 00:14:02,552
and I look at medical records, and I say,

351
00:14:02,552 --> 00:14:03,957
wouldn't it be amazing

352
00:14:03,957 --> 00:14:06,007
if everyone's medical records were available

353
00:14:06,007 --> 00:14:07,690
anonymously

354
00:14:07,690 --> 00:14:10,326
to research doctors?

355
00:14:10,326 --> 00:14:13,367
And when someone accesses your medical record,

356
00:14:13,367 --> 00:14:14,976
a research doctor,

357
00:14:14,976 --> 00:14:17,610
they could see, you could see which doctor

358
00:14:17,610 --> 00:14:19,470
accessed it and why,

359
00:14:19,470 --> 00:14:21,050
and you could maybe learn about

360
00:14:21,050 --> 00:14:22,680
what conditions you have.

361
00:14:22,680 --> 00:14:24,182
I think if we just did that,

362
00:14:24,182 --> 00:14:26,347
we'd save 100,000 lives this year.

363
00:14:26,347 --> 00:14:29,295
CR: Absolutely. Let me go — (Applause)

364
00:14:29,295 --> 00:14:32,057
LP: So I guess I'm just very worried that

365
00:14:32,057 --> 00:14:33,863
with Internet privacy,

366
00:14:33,863 --> 00:14:36,163
we're doing the same thing we're 
doing with medical records,

367
00:14:36,167 --> 00:14:38,696
is we're throwing out the baby with the bathwater,

368
00:14:38,696 --> 00:14:40,524
and we're not really thinking

369
00:14:40,524 --> 00:14:42,734
about the tremendous good that can come

370
00:14:42,734 --> 00:14:44,925
from people sharing information

371
00:14:44,925 --> 00:14:47,502
with the right people in the right ways.

372
00:14:47,502 --> 00:14:49,739
CR: And the necessary condition

373
00:14:49,739 --> 00:14:51,441
that people have to have confidence

374
00:14:51,441 --> 00:14:53,896
that their information will not be abused.

375
00:14:53,896 --> 00:14:55,673
LP: Yeah, and I had this problem with my voice stuff.

376
00:14:55,673 --> 00:14:57,181
I was scared to share it.

377
00:14:57,181 --> 00:14:59,071
Sergey encouraged me to do that,

378
00:14:59,071 --> 00:15:00,898
and it was a great thing to do.

379
00:15:00,898 --> 00:15:02,632
CR: And the response has been overwhelming.

380
00:15:02,632 --> 00:15:04,292
LP: Yeah, and people are super positive.

381
00:15:04,292 --> 00:15:07,125
We got thousands and thousands of people

382
00:15:07,125 --> 00:15:08,413
with similar conditions,

383
00:15:08,413 --> 00:15:11,441
which there's no data on today.

384
00:15:11,441 --> 00:15:12,797
So it was a really good thing.

385
00:15:12,797 --> 00:15:15,816
CR: So talking about the future, what is it about you

386
00:15:15,816 --> 00:15:19,574
and transportation systems?

387
00:15:19,574 --> 00:15:21,751
LP: Yeah. I guess I was just frustrated

388
00:15:21,751 --> 00:15:24,290
with this when I was at college in Michigan.

389
00:15:24,290 --> 00:15:25,740
I had to get on the bus and take it

390
00:15:25,740 --> 00:15:27,382
and wait for it.

391
00:15:27,382 --> 00:15:29,561
And it was cold and snowing.

392
00:15:29,561 --> 00:15:32,216
I did some research on how much it cost,

393
00:15:32,216 --> 00:15:38,641
and I just became a bit obsessed
with transportation systems.

394
00:15:38,641 --> 00:15:41,011
CR: And that began the idea of an automated car.

395
00:15:41,011 --> 00:15:42,705
LP: Yeah, about 18 years ago I learned about

396
00:15:42,705 --> 00:15:45,887
people working on automated cars,

397
00:15:45,887 --> 00:15:47,510
and I became fascinated by that,

398
00:15:47,510 --> 00:15:50,287
and it takes a while to 
get these projects going,

399
00:15:50,287 --> 00:15:55,384
but I'm super excited about the possibilities of that

400
00:15:55,384 --> 00:15:57,052
improving the world.

401
00:15:57,052 --> 00:16:01,578
There's 20 million people or more injured per year.

402
00:16:01,578 --> 00:16:03,564
It's the leading cause of death

403
00:16:03,564 --> 00:16:05,694
for people under 34 in the U.S.

404
00:16:05,694 --> 00:16:07,245
CR: So you're talking about saving lives.

405
00:16:07,245 --> 00:16:09,600
LP: Yeah, and also saving space

406
00:16:09,600 --> 00:16:13,515
and making life better.

407
00:16:13,515 --> 00:16:17,760
Los Angeles is half parking lots and roads,

408
00:16:17,760 --> 00:16:19,493
half of the area,

409
00:16:19,493 --> 00:16:22,320
and most cities are not far behind, actually.

410
00:16:22,320 --> 00:16:23,884
It's just crazy

411
00:16:23,884 --> 00:16:25,477
that that's what we use our space for.

412
00:16:25,477 --> 00:16:27,820
CR: And how soon will we be there?

413
00:16:27,820 --> 00:16:29,746
LP: I think we can be there very, very soon.

414
00:16:29,746 --> 00:16:33,247
We've driven well over 100,000 miles

415
00:16:33,247 --> 00:16:37,340
now totally automated.

416
00:16:37,340 --> 00:16:40,992
I'm super excited about getting that out quickly.

417
00:16:40,992 --> 00:16:43,397
CR: But it's not only you're
talking about automated cars.

418
00:16:43,397 --> 00:16:45,783
You also have this idea for bicycles.

419
00:16:45,783 --> 00:16:48,029
LP: Well at Google, we got this idea

420
00:16:48,029 --> 00:16:51,480
that we should just provide free bikes to everyone,

421
00:16:51,480 --> 00:16:54,248
and that's been amazing, most of the trips.

422
00:16:54,248 --> 00:16:55,834
You see bikes going everywhere,

423
00:16:55,834 --> 00:16:57,400
and the bikes wear out.

424
00:16:57,400 --> 00:16:58,854
They're getting used 24 hours a day.

425
00:16:58,854 --> 00:17:01,014
CR: But you want to put them above the street, too.

426
00:17:01,014 --> 00:17:02,589
LP: Well I said, how do we get people

427
00:17:02,589 --> 00:17:04,116
using bikes more?

428
00:17:04,116 --> 00:17:05,741
CR: We may have a video here.

429
00:17:05,741 --> 00:17:07,019
LP: Yeah, let's show the video.

430
00:17:07,019 --> 00:17:10,111
I just got excited about this.

431
00:17:10,111 --> 00:17:14,153
(Music)

432
00:17:16,033 --> 00:17:18,458
So this is actually how you might separate

433
00:17:18,458 --> 00:17:22,087
bikes from cars with minimal cost.

434
00:17:26,531 --> 00:17:28,286
Anyway, it looks totally crazy,

435
00:17:28,286 --> 00:17:30,613
but I was actually thinking about our campus,

436
00:17:30,613 --> 00:17:32,673
working with the Zippies and stuff,

437
00:17:32,673 --> 00:17:34,971
and just trying to get a lot more bike usage,

438
00:17:34,971 --> 00:17:36,519
and I was thinking about,

439
00:17:36,519 --> 00:17:39,350
how do you cost-effectively separate

440
00:17:39,350 --> 00:17:40,764
the bikes from traffic?

441
00:17:40,764 --> 00:17:41,914
And I went and searched,

442
00:17:41,914 --> 00:17:43,285
and this is what I found.

443
00:17:43,285 --> 00:17:45,130
And we're not actually working on this,

444
00:17:45,130 --> 00:17:46,422
that particular thing,

445
00:17:46,422 --> 00:17:48,476
but it gets your imagination going.

446
00:17:48,476 --> 00:17:50,240
CR: Let me close with this.

447
00:17:50,240 --> 00:17:52,585
Give me a sense of the philosophy 
of your own mind.

448
00:17:52,585 --> 00:17:55,073
You have this idea of [Google X].

449
00:17:55,073 --> 00:17:58,069
You don't simply want

450
00:17:58,069 --> 00:18:03,665
to go in some small, measurable arena of progress.

451
00:18:03,665 --> 00:18:05,378
LP: Yeah, I think

452
00:18:05,378 --> 00:18:07,509
many of the things we just 
talked about are like that,

453
00:18:07,509 --> 00:18:10,461
where they're really --

454
00:18:10,461 --> 00:18:14,091
I almost use the economic concept of additionality,

455
00:18:14,091 --> 00:18:16,281
which means that you're doing something

456
00:18:16,281 --> 00:18:19,229
that wouldn't happen unless 
you were actually doing it.

457
00:18:19,229 --> 00:18:22,369
And I think the more you can do things like that,

458
00:18:22,369 --> 00:18:24,440
the bigger impact you have,

459
00:18:24,440 --> 00:18:27,430
and that's about doing things

460
00:18:27,430 --> 00:18:31,037
that people might not think are possible.

461
00:18:31,037 --> 00:18:32,866
And I've been amazed,

462
00:18:32,866 --> 00:18:35,095
the more I learn about technology,

463
00:18:35,095 --> 00:18:37,291
the more I realize I don't know,

464
00:18:37,291 --> 00:18:40,628
and that's because this technological horizon,

465
00:18:40,628 --> 00:18:43,525
the thing that you can see to do next,

466
00:18:43,525 --> 00:18:45,365
the more you learn about technology,

467
00:18:45,365 --> 00:18:47,967
the more you learn what's possible.

468
00:18:47,967 --> 00:18:50,213
You learn that the balloons are possible

469
00:18:50,213 --> 00:18:52,550
because there's some material
that will work for them.

470
00:18:52,550 --> 00:18:54,929
CR: What's interesting about 
you too, though, for me,

471
00:18:54,929 --> 00:18:56,640
is that, we have lots of people

472
00:18:56,640 --> 00:18:58,782
who are thinking about the future,

473
00:18:58,782 --> 00:19:02,050
and they are going and looking
and they're coming back,

474
00:19:02,050 --> 00:19:04,177
but we never see the implementation.

475
00:19:04,177 --> 00:19:05,782
I think of somebody you knew

476
00:19:05,782 --> 00:19:08,689
and read about, Tesla.

477
00:19:08,689 --> 00:19:12,493
The principle of that for you is what?

478
00:19:12,493 --> 00:19:14,278
LP: Well, I think invention is not enough.

479
00:19:14,278 --> 00:19:15,499
If you invent something,

480
00:19:15,499 --> 00:19:18,694
Tesla invented electric power that we use,

481
00:19:18,694 --> 00:19:21,355
but he struggled to get it out to people.

482
00:19:21,355 --> 00:19:23,039
That had to be done by other people.

483
00:19:23,039 --> 00:19:24,665
It took a long time.

484
00:19:24,665 --> 00:19:28,532
And I think if we can actually combine both things,

485
00:19:28,532 --> 00:19:32,063
where we have an innovation and invention focus,

486
00:19:32,063 --> 00:19:35,035
plus the ability to really -- a company

487
00:19:35,035 --> 00:19:37,033
that can really commercialize things

488
00:19:37,033 --> 00:19:38,663
and get them to people

489
00:19:38,663 --> 00:19:40,738
in a way that's positive for the world

490
00:19:40,738 --> 00:19:42,794
and to give people hope.

491
00:19:42,794 --> 00:19:45,568
You know, I'm amazed with the Loon Project

492
00:19:45,568 --> 00:19:48,354
just how excited people were about that,

493
00:19:48,354 --> 00:19:50,168
because it gave them hope

494
00:19:50,168 --> 00:19:51,789
for the two thirds of the world

495
00:19:51,789 --> 00:19:54,515
that doesn't have Internet right now that's any good.

496
00:19:54,515 --> 00:19:56,637
CR: Which is a second thing about corporations.

497
00:19:56,637 --> 00:19:59,113
You are one of those people who believe

498
00:19:59,113 --> 00:20:01,430
that corporations are an agent of change

499
00:20:01,430 --> 00:20:02,901
if they are run well.

500
00:20:02,901 --> 00:20:04,722
LP: Yeah. I'm really dismayed

501
00:20:04,722 --> 00:20:08,016
most people think companies are basically evil.

502
00:20:08,016 --> 00:20:09,782
They get a bad rap.

503
00:20:09,782 --> 00:20:12,023
And I think that's somewhat correct.

504
00:20:12,023 --> 00:20:14,893
Companies are doing the same incremental thing

505
00:20:14,893 --> 00:20:16,656
that they did 50 years ago

506
00:20:16,656 --> 00:20:18,287
or 20 years ago.

507
00:20:18,287 --> 00:20:19,657
That's not really what we need.

508
00:20:19,657 --> 00:20:21,875
We need, especially in technology,

509
00:20:21,875 --> 00:20:23,992
we need revolutionary change,

510
00:20:23,992 --> 00:20:25,405
not incremental change.

511
00:20:25,405 --> 00:20:26,574
CR: You once said, actually,

512
00:20:26,574 --> 00:20:28,392
as I think I've got this about right,

513
00:20:28,392 --> 00:20:30,037
that you might consider,

514
00:20:30,037 --> 00:20:31,790
rather than giving your money,

515
00:20:31,790 --> 00:20:35,110
if you were leaving it to some cause,

516
00:20:35,110 --> 00:20:37,116
just simply giving it to Elon Musk,

517
00:20:37,116 --> 00:20:38,279
because you had confidence

518
00:20:38,279 --> 00:20:40,121
that he would change the future,

519
00:20:40,121 --> 00:20:41,898
and that you would therefore —

520
00:20:41,898 --> 00:20:43,482
LP: Yeah, if you want to go Mars,

521
00:20:43,482 --> 00:20:45,203
he wants to go to Mars,

522
00:20:45,203 --> 00:20:47,174
to back up humanity,

523
00:20:47,174 --> 00:20:48,846
that's a worthy goal, but it's a company,

524
00:20:48,846 --> 00:20:51,401
and it's philanthropical.

525
00:20:51,401 --> 00:20:54,353
So I think we aim to do kind of similar things.

526
00:20:54,353 --> 00:20:57,340
And I think, you ask, we have a lot of employees

527
00:20:57,340 --> 00:21:00,655
at Google who have become pretty wealthy.

528
00:21:00,655 --> 00:21:03,175
People make a lot of money in technology.

529
00:21:03,175 --> 00:21:05,331
A lot of people in the room are pretty wealthy.

530
00:21:05,331 --> 00:21:07,645
You're working because you
want to change the world.

531
00:21:07,645 --> 00:21:09,407
You want to make it better.

532
00:21:09,407 --> 00:21:12,852
Why isn't the company that you work for

533
00:21:12,852 --> 00:21:14,795
worthy not just of your time

534
00:21:14,795 --> 00:21:16,946
but your money as well?

535
00:21:16,946 --> 00:21:18,668
I mean, but we don't have a concept of that.

536
00:21:18,668 --> 00:21:20,972
That's not how we think about companies,

537
00:21:20,972 --> 00:21:22,439
and I think it's sad,

538
00:21:22,439 --> 00:21:26,206
because companies are most of our effort.

539
00:21:26,206 --> 00:21:28,721
They're where most of people's time is,

540
00:21:28,721 --> 00:21:30,575
where a lot of the money is,

541
00:21:30,575 --> 00:21:32,927
and so I think I'd like for us to help out

542
00:21:32,927 --> 00:21:34,053
more than we are.

543
00:21:34,053 --> 00:21:35,774
CR: When I close conversations with lots of people,

544
00:21:35,774 --> 00:21:37,553
I always ask this question:

545
00:21:37,553 --> 00:21:39,068
What state of mind,

546
00:21:39,068 --> 00:21:40,877
what quality of mind is it

547
00:21:40,877 --> 00:21:42,644
that has served you best?

548
00:21:42,644 --> 00:21:45,165
People like Rupert Murdoch have said curiosity,

549
00:21:45,165 --> 00:21:47,793
and other people in the media have said that.

550
00:21:47,793 --> 00:21:50,817
Bill Gates and Warren Buffett have said focus.

551
00:21:50,817 --> 00:21:52,244
What quality of mind,

552
00:21:52,244 --> 00:21:53,618
as I leave this audience,

553
00:21:53,618 --> 00:21:57,148
has enabled you to think about the future

554
00:21:57,148 --> 00:21:58,795
and at the same time

555
00:21:58,795 --> 00:22:01,000
change the present?

556
00:22:01,000 --> 00:22:02,670
LP: You know, I think the most important thing --

557
00:22:02,670 --> 00:22:04,282
I looked at lots of companies

558
00:22:04,282 --> 00:22:07,585
and why I thought they don't succeed over time.

559
00:22:07,585 --> 00:22:10,418
We've had a more rapid turnover of companies.

560
00:22:10,418 --> 00:22:13,187
And I said, what did they fundamentally do wrong?

561
00:22:13,187 --> 00:22:15,354
What did those companies all do wrong?

562
00:22:15,354 --> 00:22:18,626
And usually it's just that they missed the future.

563
00:22:18,626 --> 00:22:21,070
And so I think, for me,

564
00:22:21,070 --> 00:22:23,494
I just try to focus on that and say,

565
00:22:23,494 --> 00:22:25,678
what is that future really going to be

566
00:22:25,678 --> 00:22:27,465
and how do we create it,

567
00:22:27,465 --> 00:22:32,132
and how do we cause our organization,

568
00:22:32,132 --> 00:22:34,572
to really focus on that

569
00:22:34,572 --> 00:22:37,897
and drive that at a really high rate?

570
00:22:37,897 --> 00:22:39,257
And so that's been curiosity,

571
00:22:39,257 --> 00:22:40,990
it's been looking at things

572
00:22:40,990 --> 00:22:42,708
people might not think about,

573
00:22:42,708 --> 00:22:45,813
working on things that no one else is working on,

574
00:22:45,813 --> 00:22:49,119
because that's where the additionality really is,

575
00:22:49,119 --> 00:22:50,670
and be willing to do that,

576
00:22:50,670 --> 00:22:52,052
to take that risk.

577
00:22:52,052 --> 00:22:53,117
Look at Android.

578
00:22:53,117 --> 00:22:55,902
I felt guilty about working on Android

579
00:22:55,902 --> 00:22:57,218
when it was starting.

580
00:22:57,218 --> 00:22:59,176
It was a little startup we bought.

581
00:22:59,176 --> 00:23:01,846
It wasn't really what we were really working on.

582
00:23:01,846 --> 00:23:04,341
And I felt guilty about spending time on that.

583
00:23:04,341 --> 00:23:05,795
That was stupid.

584
00:23:05,795 --> 00:23:06,846
That was the future, right?

585
00:23:06,846 --> 00:23:09,131
That was a good thing to be working on.

586
00:23:09,131 --> 00:23:10,548
CR: It is great to see you here.

587
00:23:10,548 --> 00:23:12,008
It's great to hear from you,

588
00:23:12,008 --> 00:23:14,305
and a pleasure to sit at this table with you.

589
00:23:14,305 --> 00:23:15,233
Thanks, Larry.

590
00:23:15,233 --> 00:23:17,336
LP: Thank you.

591
00:23:17,336 --> 00:23:21,268
(Applause)

592
00:23:21,268 --> 00:23:24,579
CR: Larry Page.

